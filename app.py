"""
Gradio Workout Logger + ä½ çš„æ•™ç·´ï¼ˆGroqï¼‰â€” app.pyï¼ˆç©©å®šç‰ˆï¼‰
- Records çš„ Item æ”¹ç‚ºã€Œä¸‹æ‹‰ï¼‹å¯è¼¸å…¥ã€ï¼Œä¸¦æ–°å¢ã€ŒğŸ”„ æ›´æ–°é¸å–®ã€æŒ‰éˆ•
- ä¿®æ­£æ‰€æœ‰å¯èƒ½çš„æœªçµæŸå­—ä¸²ï¼ˆunterminated string literalï¼‰
- ä¿ç•™åŠŸèƒ½ï¼šé›²ç«¯åŒæ­¥ã€10 åˆ†é˜è¦†å¯«ã€Item ä¸‹æ‹‰è¨˜æ†¶ã€è¡Œå‹•ç‰ˆäº”è¡Œé¡¯ç¤ºã€Note å¦è¡Œï¼‹å°åŒ—æ™‚å€æ™‚é–“ï¼ˆ12hã€ä¸è£œ 0ï¼‰ã€æ•™ç·´ä¸²æµå¯è®€å–æœ€è¿‘ç´€éŒ„
"""
from __future__ import annotations
import os, json, hashlib, html, math
from pathlib import Path
from typing import List, Optional, Tuple
from datetime import datetime, date, timedelta, timezone

# ä¾è³´
import gradio as gr
import pandas as pd


# Groq
try:
    from groq import Groq
except ImportError:
    os.system('pip install groq')
    from groq import Groq

# Google Sheets
try:
    import gspread
except ImportError:
    os.system('pip install gspread google-auth google-auth-oauthlib')
    import gspread

# ---------------- å¸¸æ•¸ ----------------
APP_TITLE = "Workout Logger"
APP_VERSION = "v1.2"  # Update: ç§»é™¤æ™‚å€è¨»è¨˜ï¼Œæ¢å¾©ç°¡æ½”
RECORDS_CSV = Path("workout_records.csv")
ITEMS_JSON = Path("known_items.json")
NUM_SETS = 5
WINDOW_MINUTES = 10
SHEET_ID = "1qWH-FQKqAMLXdN2uV4fcLIk5URRjBwY7nELznZ352og"
SHEET_TITLE_ENV = os.getenv("SHEET_TITLE", "records")

# Groq è¨­å®š
GROQ_API_KEY = os.getenv("groq_key")
try:
    groq_client = Groq(api_key=GROQ_API_KEY) if GROQ_API_KEY else None
except Exception:
    groq_client = None

SYSTEM_PROMPT = (
    "ä½ æ˜¯ä¸€å€‹è¬›ç¹é«”ä¸­æ–‡(Zh-tw)çš„å¥èº«æ•™ç·´ï¼Œä½ å¾ˆæ¨‚è§€ã€æœƒé¼“å‹µäººï¼Œä¹Ÿæœƒè¬›æœ‰è¶£çš„ç¬‘è©±ã€‚"
    "ç„¡è«–å­¸ç”Ÿå•ä»€éº¼å•é¡Œï¼Œéƒ½ç›¡é‡æŠŠè©±é¡Œå¼•å°è‡³é‹å‹•èˆ‡å¥èº«ã€‚è«‹ç”¨å£èªã€çŸ­æ®µè½ï¼Œ"
    "æä¾›å…·é«”å¯è¡Œçš„è¨“ç·´å»ºè­°ï¼ˆå‹•ä½œ/çµ„æ•¸/é‡é‡æˆ–RPEï¼‰ï¼Œä¸¦é©åº¦æé†’å®‰å…¨èˆ‡æš–èº«æ”¾é¬†ã€‚"
)
GROQ_MODEL = "llama-3.3-70b-versatile"

# é›²ç«¯ç‹€æ…‹
CLOUD_LAST_ERROR = ""
CLOUD_WS_TITLE: Optional[str] = None

# ---------------- Google Sheets å·¥å…· ----------------

def _gs_client() -> Optional[gspread.Client]:
    try:
        sa_json = os.getenv("gspread_service_json") or os.getenv("GOOGLE_SERVICE_ACCOUNT_JSON")
        if sa_json:
            return gspread.service_account_from_dict(json.loads(sa_json))
        return gspread.service_account()
    except Exception:
        return None

def _get_target_ws(sh: gspread.Spreadsheet) -> gspread.Worksheet:
    global CLOUD_WS_TITLE
    prefer = [SHEET_TITLE_ENV, "records", "record"]
    try:
        titles = [ws.title for ws in sh.worksheets()]
    except Exception:
        titles = []
    for t in prefer:
        if t in titles:
            CLOUD_WS_TITLE = t
            return sh.worksheet(t)
    if titles:
        CLOUD_WS_TITLE = titles[0]
        return sh.worksheet(titles[0])
    CLOUD_WS_TITLE = SHEET_TITLE_ENV
    return sh.add_worksheet(title=SHEET_TITLE_ENV, rows=1000, cols=30)

def ensure_records_header(ws: gspread.Worksheet):
    cols = ["date", "item"]
    for s in range(1, NUM_SETS + 1):
        cols += [f"set{s}_kg", f"set{s}_reps"]
    cols += ["note", "total_volume_kg", "created_at"]
    try:
        header = ws.row_values(1)
    except Exception:
        header = []
    if header != cols:
        ws.clear()
        ws.update(range_name="A1", values=[cols])

def _open_ws(client: gspread.Client) -> gspread.Worksheet:
    sh = client.open_by_key(SHEET_ID)
    ws = _get_target_ws(sh)
    ensure_records_header(ws)
    return ws

def read_cloud_df() -> Optional[pd.DataFrame]:
    global CLOUD_LAST_ERROR
    cli = _gs_client()
    if not cli:
        CLOUD_LAST_ERROR = "ç„¡æ³•å»ºç«‹ Google æ†‘è­‰ï¼ˆæœªè¨­å®š service account æˆ–æª”æ¡ˆè·¯å¾‘ï¼‰ã€‚"
        return None
    try:
        ws = _open_ws(cli)
        rows = ws.get_all_values()
        if not rows:
            return None
        header = rows[0]
        data = rows[1:] if len(rows) > 1 else []
        df = pd.DataFrame(data, columns=header) if data else pd.DataFrame(columns=header)
        # æ•¸å€¼æ¬„è½‰å‹
        for s in range(1, NUM_SETS + 1):
            for sub in ("kg", "reps"):
                col = f"set{s}_{sub}"
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors="coerce")
        if "total_volume_kg" in df.columns:
            df["total_volume_kg"] = pd.to_numeric(df["total_volume_kg"], errors="coerce")
        CLOUD_LAST_ERROR = ""
        return df
    except Exception as e:
        CLOUD_LAST_ERROR = f"è®€å–é›²ç«¯å¤±æ•—ï¼š{e}"
        return None

def write_cloud_df(df: pd.DataFrame) -> Tuple[bool, int]:
    global CLOUD_LAST_ERROR
    cli = _gs_client()
    if not cli:
        CLOUD_LAST_ERROR = "ç„¡æ³•å»ºç«‹ Google æ†‘è­‰ï¼ˆæœªè¨­å®š service account æˆ–æª”æ¡ˆè·¯å¾‘ï¼‰ã€‚"
        return False, 0
    try:
        ws = _open_ws(cli)
        cols = ["date", "item"] + sum(([f"set{s}_kg", f"set{s}_reps"] for s in range(1, NUM_SETS + 1)), []) + ["note", "total_volume_kg", "created_at"]
        out = df.copy()
        for c in cols:
            if c not in out.columns:
                out[c] = ""
        out = out[cols].fillna("")
        values = [[x if isinstance(x, (int, float, str)) else ("" if x is None else str(x)) for x in row] for row in out.values.tolist()]
        ws.clear()
        ws.update(range_name="A1", values=[cols] + values)
        try:
            ws.resize(rows=max(2, len(values) + 1), cols=len(cols))
        except Exception:
            pass
        CLOUD_LAST_ERROR = ""
        return True, len(values)
    except Exception as e:
        CLOUD_LAST_ERROR = f"å¯«å…¥é›²ç«¯å¤±æ•—ï¼š{e}"
        return False, 0

# æœ¬åœ° CSV å‚™æ´
def ensure_records_csv():
    if not RECORDS_CSV.exists():
        cols = ["date", "item"]
        for s in range(1, NUM_SETS + 1):
            cols += [f"set{s}_kg", f"set{s}_reps"]
        cols += ["note", "total_volume_kg", "created_at"]
        pd.DataFrame(columns=cols).to_csv(RECORDS_CSV, index=False, encoding="utf-8")

def load_local_df() -> pd.DataFrame:
    ensure_records_csv()
    try:
        return pd.read_csv(RECORDS_CSV)
    except Exception:
        return pd.DataFrame()

def write_local_df(df: pd.DataFrame):
    df.to_csv(RECORDS_CSV, index=False, encoding="utf-8")

# å°è£ï¼šè®€å¯«å„ªå…ˆé›²ç«¯
def load_records_df() -> pd.DataFrame:
    df = read_cloud_df()
    return df if df is not None else load_local_df()

def save_records_df(df: pd.DataFrame) -> Tuple[bool, int]:
    ok, rows = write_cloud_df(df)
    write_local_df(df)
    return ok, rows

def cloud_status_line() -> str:
    df = read_cloud_df()
    target = CLOUD_WS_TITLE or SHEET_TITLE_ENV
    ok = df is not None
    count = 0 if df is None else len(df)
    status = "å·²é€£ç·šè‡³é›²ç«¯è©¦ç®—è¡¨ âœ…" if ok else f"æœªé€£ç·šè‡³é›²ç«¯ï¼ˆæ”¹ç”¨æœ¬æ©Ÿå‚™æ´ï¼‰âŒ  {CLOUD_LAST_ERROR}"
    return f"**Cloud**ï¼š{status}ï¼Œåˆ†é ï¼š{target}ï¼Œç›®å‰åˆ—æ•¸ï¼š{count}"

# ---------------- å°å·¥å…· ----------------
def load_known_items() -> List[str]:
    if ITEMS_JSON.exists():
        try:
            return json.loads(ITEMS_JSON.read_text(encoding="utf-8"))
        except Exception:
            return []
    return []

# æ–°å¢ï¼šå–å¾—å°åŒ—æ™‚é–“ (UTC+8) çš„ Helper
def get_now_tpe() -> datetime:
    return datetime.now(timezone(timedelta(hours=8)))

def save_known_items(items: List[str]):
    uniq: List[str] = []
    for it in items:
        it = (it or "").strip()
        if it and it not in uniq:
            uniq.append(it)
    ITEMS_JSON.write_text(json.dumps(uniq, ensure_ascii=False, indent=2), encoding="utf-8")

def get_all_item_choices() -> List[str]:
    seen: List[str] = []
    df = read_cloud_df()
    if df is not None and not df.empty and "item" in df.columns:
        counts = df["item"].dropna().astype(str).str.strip().value_counts()
        seen += [x for x in counts.index.tolist() if x]
    else:
        if RECORDS_CSV.exists():
            try:
                df_local = pd.read_csv(RECORDS_CSV)
                if "item" in df_local.columns:
                    counts = df_local["item"].dropna().astype(str).str.strip().value_counts()
                    seen += [x for x in counts.index.tolist() if x]
            except Exception:
                pass
    for it in load_known_items():
        if it and it not in seen:
            seen.append(it)
    return seen

def _fmt_num(n):
    if n in (None, "", "nan", "NaN", "NAN"):
        return ""
    try:
        f = float(n)
        if math.isnan(f):
            return ""
        return str(int(f)) if float(f).is_integer() else str(f)
    except Exception:
        return str(n)

def compute_total_volume(kg_list: List[float|None], reps_list: List[int|None]) -> float:
    total = 0.0
    for k, r in zip(kg_list, reps_list):
        if k is None or r is None:
            continue
        try:
            total += float(k) * int(r)
        except Exception:
            pass
    return round(total, 2)

def hash_entry(row: dict) -> str:
    key = json.dumps({k: row.get(k) for k in [
        "date", "item",
        *[f"set{i}_kg" for i in range(1, NUM_SETS + 1)],
        *[f"set{i}_reps" for i in range(1, NUM_SETS + 1)],
        "note",
    ]}, sort_keys=True, ensure_ascii=False)
    return hashlib.sha256(key.encode("utf-8")).hexdigest()

# æ™‚é–“é¡¯ç¤ºï¼ˆå°åŒ—æ™‚å€ã€ä¸Šåˆ/ä¸‹åˆ/æ™šä¸Šã€12 å°æ™‚åˆ¶ã€ä¸è£œ 0ï¼‰
def to_tpe_time_str(created_at: str) -> str:
    if not created_at:
        return ""
    try:
        # Update: å˜—è©¦è§£æç‚º Naive Time ä¸¦è¦–ç‚º TPEï¼Œæˆ–è™•ç†èˆŠæœ‰ Aware Time
        ts = pd.to_datetime(created_at)
        if ts.tzinfo is None:
             # è‹¥ç„¡æ™‚å€è³‡è¨Šï¼Œé è¨­ç‚ºå°åŒ—æ™‚é–“ (TPE is UTC+8)
            ts = ts.tz_localize(timezone(timedelta(hours=8)))
        else:
            # è‹¥æœ‰æ™‚å€è³‡è¨Šï¼Œè½‰æ›è‡³ TPE
            ts = ts.tz_convert(timezone(timedelta(hours=8)))
    except Exception:
        return ""
    
    try:
        # å› ç‚ºå·²ç¶“æ˜¯ TPE aware
        h24 = int(ts.strftime("%H"))
        m = ts.strftime("%M")
        period = "ä¸Šåˆ"
        if 12 <= h24 <= 17:
            period = "ä¸‹åˆ"
        elif 18 <= h24 <= 23:
            period = "æ™šä¸Š"
        h12 = ((h24 - 1) % 12) + 1
        return f"{period} {h12}:{m}"
    except Exception:
        return ""

# ---------------- HTML å‘ˆç¾ï¼ˆäº”è¡Œ + Note å¦èµ·ä¸€è¡Œï¼‰ ----------------
def df_to_html_compact5(df: pd.DataFrame) -> str:
    if df is None or df.empty:
        return "<div class='records-empty'>ç›®å‰æ²’æœ‰ç´€éŒ„</div>"
    if "note" in df.columns:
        cols = [c for c in df.columns if c != "note"] + ["note"]
        df = df[cols]

    cards: List[str] = []
    for _, row in df.iterrows():
        date_s = row.get("date", "") or ""
        item_s = row.get("item", "") or ""
        note_s = row.get("note", "") or ""
        total_s = _fmt_num(row.get("total_volume_kg", ""))
        created_s = row.get("created_at", "") or ""
        time_tpe = to_tpe_time_str(created_s)

        set_lines: List[str] = []
        for i in range(1, NUM_SETS + 1):
            kg = _fmt_num(row.get(f"set{i}_kg", ""))
            rp = _fmt_num(row.get(f"set{i}_reps", ""))
            kg_txt = (kg + "kg") if kg else ""
            rp_txt = (rp + "r") if rp else ""
            set_lines.append(
                f"<tr><td class='sidx'>{i}</td><td class='kg nowrap'>{kg_txt}</td><td class='r nowrap'>{rp_txt}</td></tr>"
            )
        lines_html = "".join(set_lines)
        note_html = (
            f"<tr class='note-row'><td class='note-cell' colspan='3'>"
            f"<b>Noteï¼š</b>{html.escape(str(note_s))}<span class='time'>ï¼ˆ{html.escape(time_tpe)}ï¼‰</span>"
            f"</td></tr>"
        )

        header_left = html.escape(str(date_s)) + " Â· " + html.escape(str(item_s))
        header_right = ("Î£ " + html.escape(str(total_s)) + " kg") if total_s else ""

        card_html = (
            "<div class='rec-card'>"
            "<div class='rec-header'>"
            f"<div class='left nowrap'>{header_left}</div>"
            f"<div class='right nowrap'>{header_right}</div>"
            "</div>"
            "<table class='rec-sets'><tbody>"
            f"{lines_html}{note_html}"
            "</tbody></table>"
            "</div>"
        )
        cards.append(card_html)

    return "<div class='records-cards'>" + "".join(cards) + "</div>"

# ---------------- å„²å­˜é‚è¼¯ ----------------
def save_button_clicked(date_str: str, item_name: str,
                        set1kg, set1reps, set2kg, set2reps, set3kg, set3reps, set4kg, set4reps, set5kg, set5reps,
                        note: str):
    # æ—¥æœŸï¼ˆç©ºç™½â†’ä»Šå¤©ï¼Œæ”¹ç”¨å°åŒ—æ™‚é–“ï¼‰
    if not date_str or not str(date_str).strip():
        dt = get_now_tpe().date()
    else:
        try:
            dt = pd.to_datetime(date_str).date()
        except Exception:
            return "æ—¥æœŸæ ¼å¼éŒ¯èª¤ï¼Œè«‹ç”¨ YYYY-MM-DD", gr.update(), "", gr.update(), cloud_status_line()

    item_name = (item_name or "").strip()
    if not item_name:
        return "æ²’æœ‰å¯å­˜çš„è³‡æ–™ï¼šè«‹è‡³å°‘å¡«ä¸€å€‹ Item åç¨±", gr.update(), "", gr.update(), cloud_status_line()

    to_f = lambda x: None if x in ("", None) else float(x)
    to_i = lambda x: None if x in ("", None) else int(x)

    kg_vals = [to_f(set1kg), to_f(set2kg), to_f(set3kg), to_f(set4kg), to_f(set5kg)]
    reps_vals = [to_i(set1reps), to_i(set2reps), to_i(set3reps), to_i(set4reps), to_i(set5reps)]

    sets_kv = {}
    for idx, (kg, rp) in enumerate(zip(kg_vals, reps_vals), start=1):
        sets_kv[f"set{idx}_kg"] = kg
        sets_kv[f"set{idx}_reps"] = rp

    total_volume = compute_total_volume(kg_vals, reps_vals)
    
    # Update: å»ºç«‹æ™‚é–“æ”¹ç”¨å°åŒ—æ™‚é–“ï¼Œä½†å„²å­˜æ™‚ä¸å¸¶æ™‚å€è³‡è¨Š (Naive) ä»¥ç¬¦åˆéœ€æ±‚
    now_tpe = get_now_tpe()
    created_at_str = now_tpe.strftime('%Y-%m-%dT%H:%M:%S')  # ISO format without offset

    new_row = {
        "date": dt.isoformat(),
        "item": item_name,
        **sets_kv,
        "note": note or "",
        "total_volume_kg": total_volume,
        "created_at": created_at_str,
    }

    new_hash = hash_entry(new_row)
    df = load_records_df()

    # æ‰¾åŒæ—¥åŒ item æœ€è¿‘ä¸€ç­†
    idx_recent = None
    recent_row = None
    if df is not None and not df.empty:
        try:
            tmp = df.copy()
            # è®€å–æ™‚ï¼Œç¢ºä¿ tmp["created_at_dt"] ç‚º TPE aware
            tmp["created_at_dt"] = pd.to_datetime(tmp.get("created_at"), errors="coerce")
            
            mask_naive = tmp["created_at_dt"].apply(lambda x: x.tzinfo is None if pd.notnull(x) else False)
            if mask_naive.any():
                tmp.loc[mask_naive, "created_at_dt"] = tmp.loc[mask_naive, "created_at_dt"].dt.tz_localize(timezone(timedelta(hours=8)))
            
            mask_aware = ~mask_naive
            if mask_aware.any():
                tmp.loc[mask_aware, "created_at_dt"] = tmp.loc[mask_aware, "created_at_dt"].dt.tz_convert(timezone(timedelta(hours=8)))

            same = (tmp["date"].astype(str) == new_row["date"]) & (tmp["item"].astype(str) == new_row["item"])
            same_df = tmp[same].sort_values("created_at_dt", ascending=False)
            if not same_df.empty:
                idx_recent = same_df.index[0]
                recent_row = df.loc[idx_recent].to_dict()
        except Exception:
            pass

    if recent_row is not None and hash_entry(recent_row) == new_hash:
        merged = get_all_item_choices()
        latest = load_records_df()
        latest_html = df_to_html_compact5(latest.tail(20)) if latest is not None and not latest.empty else ""
        return ("å…§å®¹æœªè®Šæ›´ï¼šæœªå„²å­˜ã€‚", gr.update(choices=merged), latest_html, gr.update(interactive=False), cloud_status_line())

    # Update: 10 åˆ†é˜å…§é‡è¤‡å„²å­˜é‚è¼¯ -> ç§»é™¤ã€Œæ‰€æœ‰ã€ç¬¦åˆæ¢ä»¶çš„èˆŠç´€éŒ„ï¼ˆè¦†å¯«ï¼‰
    replaced = False
    if df is not None and not df.empty:
        try:
            tmp = df.copy()
            # ç¢ºä¿èˆŠè³‡æ–™æ™‚é–“æ¬„ä½ç‚º TPE aware (çµ±ä¸€åŸºæº–)
            tmp["created_at_dt"] = pd.to_datetime(tmp.get("created_at"), errors="coerce")
            
            mask_naive = tmp["created_at_dt"].apply(lambda x: x.tzinfo is None if pd.notnull(x) else False)
            if mask_naive.any():
                tmp.loc[mask_naive, "created_at_dt"] = tmp.loc[mask_naive, "created_at_dt"].dt.tz_localize(timezone(timedelta(hours=8)))
            
            mask_aware = ~mask_naive
            if mask_aware.any():
                tmp.loc[mask_aware, "created_at_dt"] = tmp.loc[mask_aware, "created_at_dt"].dt.tz_convert(timezone(timedelta(hours=8)))
            
            # now_tpe å·²ç¶“æ˜¯ TPE aware
            mask_target = (tmp["date"].astype(str) == new_row["date"]) & (tmp["item"].astype(str) == new_row["item"])
            mask_window = (now_tpe - tmp["created_at_dt"]) <= timedelta(minutes=WINDOW_MINUTES)
            
            indices_to_drop = tmp[mask_target & mask_window].index
            
            if not indices_to_drop.empty:
                df = df.drop(index=indices_to_drop)
                replaced = True
        except Exception:
            pass

    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)

    if "note" in df.columns:
        cols = [c for c in df.columns if c != "note"] + ["note"]
        df = df[cols]

    ok_cloud, total_rows = save_records_df(df)

    msg = ("å·²è¦†å¯«æœ€è¿‘ 10 åˆ†é˜å…§çš„èˆŠç´€éŒ„ã€‚" if replaced else "å·²å„²å­˜ 1 ç­†ã€‚") + f"ï¼ˆæ—¥æœŸï¼š{dt.isoformat()}ï¼‰"
    if ok_cloud:
        msg += f"ï½œé›²ç«¯åŒæ­¥âœ…ï½œåˆ†é ï¼š{CLOUD_WS_TITLE or SHEET_TITLE_ENV}ï½œç¸½åˆ—æ•¸ï¼š{total_rows}"
    else:
        extra = f"ï¼ˆ{CLOUD_LAST_ERROR}ï¼‰" if CLOUD_LAST_ERROR else ""
        msg += f"ï½œé›²ç«¯åŒæ­¥âŒ {extra}"

    known = load_known_items()
    if item_name not in known:
        known.append(item_name)
        save_known_items(known)

    merged = get_all_item_choices()
    latest = load_records_df()
    latest_html = df_to_html_compact5(latest.tail(20)) if latest is not None and not latest.empty else ""
    return (msg, gr.update(choices=merged), latest_html, gr.update(interactive=True), cloud_status_line())

# ---------------- æœå°‹ ----------------
def search_records(date_from: str, date_to: str, item_filter: str) -> pd.DataFrame:
    df = load_records_df()
    if date_from:
        try:
            df = df[df["date"] >= pd.to_datetime(date_from).date().isoformat()]
        except Exception:
            pass
    if date_to:
        try:
            df = df[df["date"] <= pd.to_datetime(date_to).date().isoformat()]
        except Exception:
            pass
    if item_filter:
        df = df[df["item"].astype(str).str.contains(item_filter, case=False, na=False)]
    if not df.empty:
        try:
            df["created_at_dt"] = pd.to_datetime(df["created_at"], errors="coerce")
            df = df.sort_values(["date", "created_at_dt"], ascending=[False, False])
            df = df.drop(columns=["created_at_dt"], errors="ignore")
        except Exception:
            pass
        if "note" in df.columns:
            cols = [c for c in df.columns if c != "note"] + ["note"]
            df = df[cols]
    return df

def search_records_html(date_from: str, date_to: str, item_filter: str) -> str:
    return df_to_html_compact5(search_records(date_from, date_to, item_filter))

# ---------------- æ•™ç·´ä¸Šä¸‹æ–‡ ----------------
def _truncate(s: str, n: int) -> str:
    s = str(s or "")
    return s if len(s) <= n else s[: n - 1] + "â€¦"

def make_coach_context(days: int = 60, max_items: int = 8, max_recent: int = 10) -> str:
    df = load_records_df()
    if df is None or df.empty:
        return "ï¼ˆç›®å‰æ²’æœ‰é›²ç«¯ç´€éŒ„ï¼‰"
    f = df.copy()
    try:
        f["date_dt"] = pd.to_datetime(f["date"], errors="coerce")
        cutoff = pd.Timestamp.today().normalize() - pd.Timedelta(days=days)
        f = f[f["date_dt"] >= cutoff]
    except Exception:
        pass
    if f.empty:
        return f"ï¼ˆæœ€è¿‘ {days} å¤©æ²’æœ‰ç´€éŒ„ï¼‰"

    lines = [f"æœŸé–“ï¼šæœ€è¿‘ {days} å¤©"]
    try:
        vol = f.groupby("item", dropna=False)["total_volume_kg"].sum(min_count=1).sort_values(ascending=False)
    except Exception:
        vol = pd.Series(dtype=float)
    try:
        cnt = f["item"].value_counts()
    except Exception:
        cnt = pd.Series(dtype=int)
    try:
        last_date = f.groupby("item", dropna=False)["date"].max()
    except Exception:
        last_date = pd.Series(dtype=str)

    items = list(cnt.index[:max_items]) if not cnt.empty else f["item"].dropna().unique().tolist()[:max_items]
    for it in items:
        c = int(cnt.get(it, 0)) if not cnt.empty else 0
        v = vol.get(it, float('nan')) if not vol.empty else float('nan')
        v_txt = _fmt_num(v)
        ld = last_date.get(it, "") if not last_date.empty else ""
        lines.append(f"- {it}: æ¬¡æ•¸ {c}ï¼Œç¸½é‡ {v_txt} kgï¼Œæœ€è¿‘ {ld}")

    try:
        f["created_at_dt"] = pd.to_datetime(f["created_at"], errors="coerce")
        recent = f.sort_values("created_at_dt", ascending=False).head(max_recent)
    except Exception:
        recent = f.tail(max_recent)

    lines.append("æœ€è¿‘å¹¾ç­†ï¼š")
    for _, r in recent.iterrows():
        parts: List[str] = []
        for i in range(1, NUM_SETS + 1):
            kg = _fmt_num(r.get(f"set{i}_kg"))
            rp = _fmt_num(r.get(f"set{i}_reps"))
            if kg and rp:
                parts.append(f"{kg}x{rp}")
        sets_txt = "/".join(parts)
        note_txt = _truncate(r.get("note", ""), 40)
        total_txt = _fmt_num(r.get("total_volume_kg"))
        lines.append(f"- {r.get('date','')} {r.get('item','')}: {sets_txt}ï¼›å‚™è¨»ï¼š{note_txt}ï¼›total={total_txt}kg")
    return "\n".join(lines)

# ---------------- æ•™ç·´ï¼ˆä¸²æµï¼‰ ----------------
def coach_chat_stream_ctx(history, user_msg: str, use_ctx: bool, ctx_days: int):
    msg = (user_msg or "").strip()
    if not msg:
        yield history, ""
        return
    if groq_client is None:
        bot = "ï¼ˆå°šæœªè¨­å®šç’°å¢ƒè®Šæ•¸ groq_keyï¼Œè«‹è¨­å®šå¾Œé‡è©¦ã€‚ï¼‰"
        if isinstance(history, list) and (not history or isinstance(history[0], dict)):
            ui = history + [{"role": "user", "content": msg}, {"role": "assistant", "content": bot}]
        else:
            ui = (history or []) + [[msg, bot]]
        yield ui, ""
        return

    sys_content = SYSTEM_PROMPT
    if use_ctx:
        try:
            ctx = make_coach_context(int(ctx_days))
        except Exception:
            ctx = make_coach_context()
        sys_content += "\n\nã€å­¸å“¡è¿‘æœŸç´€éŒ„æ‘˜è¦ã€‘\n" + ctx

    api_messages = [{"role": "system", "content": sys_content}]

    if isinstance(history, list) and history and isinstance(history[0], dict):
        for m in history:
            if m.get("role") in ("user", "assistant"):
                api_messages.append({"role": m.get("role"), "content": m.get("content", "")})
        ui_hist = history.copy()
    else:
        for u, b in (history or []):
            if u:
                api_messages.append({"role": "user", "content": u})
            if b:
                api_messages.append({"role": "assistant", "content": b})
        ui_hist = []
        for u, b in (history or []):
            if u:
                ui_hist.append({"role": "user", "content": u})
            if b:
                ui_hist.append({"role": "assistant", "content": b})

    api_messages.append({"role": "user", "content": msg})

    try:
        completion = groq_client.chat.completions.create(
            model=GROQ_MODEL,
            messages=api_messages,
            temperature=0.7,
            max_completion_tokens=512,
            top_p=1,
            stream=True,
            stop=None,
        )
        ui_hist = ui_hist + [{"role": "user", "content": msg}, {"role": "assistant", "content": ""}]
        acc = ""
        for chunk in completion:
            delta = chunk.choices[0].delta.content or ""
            if delta:
                acc += delta
                ui_hist[-1]["content"] = acc
                yield ui_hist, ""
        return
    except Exception as e:
        ui_hist = ui_hist + [{"role": "user", "content": msg}, {"role": "assistant", "content": f"æŠ±æ­‰ï¼ŒGroq å‘¼å«å¤±æ•—ï¼š{e}"}]
        yield ui_hist, ""

# ---------------- JavaScript (Rest Timer) ----------------
def get_rest_timer_js(elem_id):
    return f"""
    (x) => {{
        // å–å¾—æŒ‰éˆ•å…ƒç´ 
        const btn = document.querySelector('#{elem_id} button') || document.querySelector('#{elem_id}');
        if (!btn) return;
        
        // é˜²æ­¢é‡è¤‡é»æ“Š
        if (btn.classList.contains('counting')) return;
        btn.classList.add('counting');
        
        let seconds = 120; // å€’æ•¸ 120 ç§’ (2 åˆ†é˜)
        const originalText = "Rest";
        
        // æ’­æ”¾æç¤ºéŸ³ (Web Audio API æ¨¡æ“¬æ‹³æ“Šéˆ´è²)
        const playSound = () => {{
            try {{
                const ctx = new (window.AudioContext || window.webkitAudioContext)();
                const t = ctx.currentTime;
                
                // æ¨¡æ“¬éˆ´è²ï¼šæ··åˆå…©å€‹é »ç‡
                const osc1 = ctx.createOscillator();
                const gain1 = ctx.createGain();
                osc1.connect(gain1);
                gain1.connect(ctx.destination);
                osc1.type = 'square'; // æ–¹æ³¢è¼ƒæœ‰ç©¿é€åŠ›
                osc1.frequency.setValueAtTime(600, t);
                gain1.gain.setValueAtTime(0.3, t);
                gain1.gain.exponentialRampToValueAtTime(0.001, t + 1.2);
                
                const osc2 = ctx.createOscillator();
                const gain2 = ctx.createGain();
                osc2.connect(gain2);
                gain2.connect(ctx.destination);
                osc2.type = 'sine';
                osc2.frequency.setValueAtTime(1000, t);
                gain2.gain.setValueAtTime(0.2, t);
                gain2.gain.exponentialRampToValueAtTime(0.001, t + 1.0);

                osc1.start(t);
                osc1.stop(t + 1.5);
                osc2.start(t);
                osc2.stop(t + 1.5);
            }} catch(e) {{
                console.error("Audio play failed", e);
            }}
        }};

        btn.innerText = seconds + "s";
        
        const timer = setInterval(() => {{
            seconds--;
            if (seconds > 0) {{
                btn.innerText = seconds + "s";
            }} else {{
                clearInterval(timer);
                playSound();
                btn.innerText = "Time's up";
                // 3ç§’å¾Œæ¢å¾© Rest
                setTimeout(() => {{
                    btn.innerText = originalText;
                    btn.classList.remove('counting');
                }}, 3000);
            }}
        }}, 1000);
    }}
    """

# ---------------- CSS ----------------
CSS = """
.records-cards { display: grid; gap: 10px; }
.rec-card { border-bottom: 4px solid rgba(255,255,255,0.35); padding: 8px 6px; }
.rec-header { display:flex; justify-content: space-between; align-items: baseline; margin-bottom: 6px; }
.rec-header .left { font-weight: 600; }
.rec-header .right { opacity: .8; font-size: .95em; }
.nowrap { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; }
.rec-sets { width: 100%; border-collapse: collapse; table-layout: fixed; }
.rec-sets td { border: 1px solid rgba(255,255,255,0.15); padding: 4px; vertical-align: top; }
.rec-sets td.sidx { width: 26px; text-align: center; opacity: .8; }
.rec-sets td.kg, .rec-sets td.r { width: 56px; }
.note-row td { background: rgba(255,255,255,0.04); }
.rec-sets td.note-cell { padding: 8px 6px; }
.rec-sets td.note-cell .time { margin-left: .5em; opacity:.65; font-size:.9em; }
@media (max-width: 480px) {
  .rec-sets td.kg, .rec-sets td.r { width: 48px; }
}
"""

# ---------------- ä»‹é¢ ----------------
def _today_iso() -> str:
    # Update: é è¨­æ—¥æœŸæ”¹ç‚ºå°åŒ—æ™‚é–“
    return get_now_tpe().date().isoformat()

with gr.Blocks(title=f"{APP_TITLE} {APP_VERSION}", theme=gr.themes.Soft(), css=CSS) as demo:
    gr.Markdown(f"""# ğŸ‹ï¸â€â™‚ï¸ Workout Logger {APP_VERSION} + ğŸ¤– ä½ çš„æ•™ç·´
    å¿«é€Ÿè¨˜éŒ„é‡é‡è¨“ç·´èˆ‡æŸ¥è©¢æ­·å²ã€‚""")

    cloud_md = gr.Markdown(cloud_status_line())

    with gr.Tabs():
        with gr.TabItem("Log"):
            # Update: é€™è£¡åŠ ä¸Šæ™‚å€è¨»è¨˜
            date_in = gr.Textbox(value="", label="Date (YYYY-MM-DD) [TPE UTC+8]")

            item_dd = gr.Dropdown(choices=get_all_item_choices(), allow_custom_value=True, value=None, label="Item åç¨±")

            with gr.Row():
                set1kg = gr.Number(label="Set 1 â€” kg", precision=2, value=None, placeholder="kg")
                set1rp = gr.Number(label="Set 1 â€” r", precision=0, value=None, placeholder="r")
                btn_rest1 = gr.Button("Rest", size="sm", min_width=60, elem_id="rest_btn_1", scale=0)
                btn_rest1.click(None, None, None, js=get_rest_timer_js("rest_btn_1"))

            with gr.Row():
                set2kg = gr.Number(label="Set 2 â€” kg", precision=2, value=None, placeholder="kg")
                set2rp = gr.Number(label="Set 2 â€” r", precision=0, value=None, placeholder="r")
                btn_rest2 = gr.Button("Rest", size="sm", min_width=60, elem_id="rest_btn_2", scale=0)
                btn_rest2.click(None, None, None, js=get_rest_timer_js("rest_btn_2"))

            with gr.Row():
                set3kg = gr.Number(label="Set 3 â€” kg", precision=2, value=None, placeholder="kg")
                set3rp = gr.Number(label="Set 3 â€” r", precision=0, value=None, placeholder="r")
                btn_rest3 = gr.Button("Rest", size="sm", min_width=60, elem_id="rest_btn_3", scale=0)
                btn_rest3.click(None, None, None, js=get_rest_timer_js("rest_btn_3"))

            with gr.Row():
                set4kg = gr.Number(label="Set 4 â€” kg", precision=2, value=None, placeholder="kg")
                set4rp = gr.Number(label="Set 4 â€” r", precision=0, value=None, placeholder="r")
                btn_rest4 = gr.Button("Rest", size="sm", min_width=60, elem_id="rest_btn_4", scale=0)
                btn_rest4.click(None, None, None, js=get_rest_timer_js("rest_btn_4"))

            with gr.Row():
                set5kg = gr.Number(label="Set 5 â€” kg", precision=2, value=None, placeholder="kg")
                set5rp = gr.Number(label="Set 5 â€” r", precision=0, value=None, placeholder="r")
                btn_rest5 = gr.Button("Rest", size="sm", min_width=60, elem_id="rest_btn_5", scale=0)
                btn_rest5.click(None, None, None, js=get_rest_timer_js("rest_btn_5"))

            note_in = gr.Textbox(label="Note", placeholder="RPEã€æ„Ÿè¦ºã€ä¸‹æ¬¡èª¿æ•´â€¦")

            save_btn = gr.Button("ğŸ’¾ Save", variant="primary")
            status_md = gr.Markdown("")
            cur = load_records_df()
            latest_html = gr.HTML(value=(df_to_html_compact5(cur.tail(20)) if (cur is not None and not cur.empty) else ""), label="æœ€è¿‘ 20 ç­†ç´€éŒ„")

            save_btn.click(
                fn=save_button_clicked,
                inputs=[date_in, item_dd,
                        set1kg, set1rp, set2kg, set2rp, set3kg, set3rp, set4kg, set4rp, set5kg, set5rp,
                        note_in],
                outputs=[status_md, item_dd, latest_html, save_btn, cloud_md],
            )

            demo.load(fn=_today_iso, inputs=None, outputs=date_in)

        with gr.TabItem("Records"):
            with gr.Row():
                q_from = gr.Textbox(label="From (YYYY-MM-DD)")
                q_to = gr.Textbox(label="To (YYYY-MM-DD)")
                # æ”¹ç‚ºä¸‹æ‹‰é¸å–®ï¼ˆå¯è¼¸å…¥ï¼‰ï¼Œé¸é …å–è‡ªæ­·å²ç´€éŒ„
                q_item = gr.Dropdown(
                    choices=get_all_item_choices(),
                    allow_custom_value=True,
                    value=None,
                    label="Itemï¼ˆä¸‹æ‹‰æˆ–è¼¸å…¥ï¼‰"
                )
            refresh_btn = gr.Button("ğŸ”„ æ›´æ–°é¸å–®")
            query_btn = gr.Button("ğŸ” Search")
            out_html = gr.HTML(value=df_to_html_compact5(load_records_df()), label="æœå°‹çµæœ")

            # åˆ·æ–°ä¸‹æ‹‰é¸å–®å…§å®¹
            refresh_btn.click(lambda: gr.update(choices=get_all_item_choices()), None, q_item)

            query_btn.click(search_records_html, inputs=[q_from, q_to, q_item], outputs=out_html)

        with gr.TabItem("ä½ çš„æ•™ç·´"):
            chatbot = gr.Chatbot(height=420, type='messages')
            user_in = gr.Textbox(placeholder="è¼¸å…¥ä½ çš„å•é¡Œï¼ŒæŒ‰ Enter æˆ–é»é€å‡ºâ€¦", label="è¨Šæ¯")
            with gr.Row():
                use_ctx = gr.Checkbox(value=True, label="æŠŠæœ€è¿‘ç´€éŒ„æä¾›çµ¦æ•™ç·´")
                ctx_days = gr.Slider(7, 180, value=60, step=1, label="æœ€è¿‘ï¼ˆå¤©ï¼‰")
            with gr.Row():
                send_btn = gr.Button("é€å‡º", variant="primary")
                clear_btn = gr.Button("æ¸…ç©º")
            send_btn.click(coach_chat_stream_ctx, inputs=[chatbot, user_in, use_ctx, ctx_days], outputs=[chatbot, user_in])
            user_in.submit(coach_chat_stream_ctx, inputs=[chatbot, user_in, use_ctx, ctx_days], outputs=[chatbot, user_in])
            clear_btn.click(lambda: ([], ""), None, [chatbot, user_in], queue=False)

    gr.Markdown("""---
**Tips**
- Item åç¨±å¯ç›´æ¥è¼¸å…¥æ–°æ–‡å­—ï¼Œä¸‹æ¬¡æœƒå‡ºç¾åœ¨ä¸‹æ‹‰é¸å–®ã€‚
- ç©ºç™½çš„æ•¸å€¼æ¬„æœƒä¿æŒç©ºç™½ï¼ˆä¸é¡¯ç¤º 0ï¼‰ã€‚
- Total Volume = âˆ‘(kg Ã— r)ã€‚
""")

if __name__ == "__main__":
    if not RECORDS_CSV.exists():
        ensure_records_csv()
    demo.launch()
